{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a082cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/simc/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy import linalg\n",
    "import ot  # Python Optimal Transport\n",
    "\n",
    "from datasets import load_from_disk, Dataset, load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bd090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载模型到: /home/ubuntu/data/model/gpt2_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/simc/lib/python3.14/site-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `snapshot_download`. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "Fetching 26 files: 100%|██████████| 26/26 [1:28:17<00:00, 203.76s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载数据集到: /home/ubuntu/data/dataset/wikitext_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 28549.30 examples/s]\n",
      "Generating train split: 100%|██████████| 36718/36718 [00:00<00:00, 636106.42 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 485966.44 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4358/4358 [00:00<00:00, 566555.40 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 36718/36718 [00:00<00:00, 1225434.29 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3760/3760 [00:00<00:00, 602275.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下载完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义你的本地存储根目录\n",
    "MODEL_PATH = \"/home/ubuntu/data/model/gpt2_model\"\n",
    "DATA_PATH = \"/home/ubuntu/data/dataset/wikitext_dataset\"\n",
    "\n",
    "# --- 1. 下载模型和分词器 ---\n",
    "print(\"正在下载模型到:\", MODEL_PATH)\n",
    "snapshot_download(\n",
    "    repo_id=\"gpt2\", \n",
    "    local_dir=MODEL_PATH,\n",
    "    local_dir_use_symlinks=False\n",
    ")\n",
    "\n",
    "# --- 2. 下载并保存数据集 ---\n",
    "print(\"正在下载数据集到:\", DATA_PATH)\n",
    "# 先下载到缓存，然后保存到指定磁盘路径\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "dataset.save_to_disk(DATA_PATH)\n",
    "\n",
    "print(\"下载完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b74dc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 开始下载模型: sentence-transformers/all-mpnet-base-v2\n",
      ">>> 目标路径: /home/ubuntu/data/model/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 473.17it/s, Materializing param=pooler.dense.weight]                        \n",
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 模型下载并保存成功！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= 配置 =================\n",
    "# 1. 你想要下载的模型名称 (SBERT 榜单推荐)\n",
    "MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "# 2. 你想要保存的本地绝对路径\n",
    "SAVE_PATH = '/home/ubuntu/data/model/all-mpnet-base-v2'\n",
    "# =======================================\n",
    "\n",
    "def download_and_save():\n",
    "    print(f\">>> 开始下载模型: {MODEL_NAME}\")\n",
    "    print(f\">>> 目标路径: {SAVE_PATH}\")\n",
    "\n",
    "    # 如果目录不存在，自动创建\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "    # 加载模型 (会自动下载)\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    \n",
    "    # 保存模型到本地\n",
    "    model.save(SAVE_PATH)\n",
    "    print(\">>> 模型下载并保存成功！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ad71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载模型到: /home/ubuntu/data/model/gpt2_large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 29 files: 100%|██████████| 29/29 [06:50<00:00, 14.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/data/model/gpt2_large'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"/home/ubuntu/data/model/gpt2_large\"\n",
    "\n",
    "print(\"正在下载模型到:\", MODEL_PATH)\n",
    "snapshot_download(\n",
    "    repo_id=\"gpt2-large\", \n",
    "    local_dir=MODEL_PATH,\n",
    "    local_dir_use_symlinks=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
